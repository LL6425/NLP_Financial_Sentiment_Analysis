{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "This notebook contains the following operations:\n",
    "\n",
    "- Data Import\n",
    "- Labelling\n",
    "- Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Packages & Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_processing import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221515</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Why Shares of Chinese Electric Car Maker NIO A...</td>\n",
       "      <td>news</td>\n",
       "      <td>What s happening\\nShares of Chinese electric c...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://invst.ly/pigqi</td>\n",
       "      <td>2060327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221516</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO only consumer gainer  Workhorse Group amon...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pje9c</td>\n",
       "      <td>2062196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ticker                                              title category  \\\n",
       "0  221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
       "1  221516    NIO  NIO only consumer gainer  Workhorse Group amon...     news   \n",
       "\n",
       "                                             content release_date  \\\n",
       "0  What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
       "1  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
       "\n",
       "          provider                     url  article_id  \n",
       "0  The Motley Fool  https://invst.ly/pigqi     2060327  \n",
       "1    Seeking Alpha  https://invst.ly/pje9c     2062196  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import News df\n",
    "\n",
    "df_filename='us_equities_news_dataset.csv'\n",
    "\n",
    "df=pd.read_csv(os.path.join(data_path, 'input', df_filename))\n",
    "\n",
    "# Visual check\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change date datatype\n",
    "\n",
    "df['release_date']=pd.to_datetime(df['release_date'], format='%Y-%m-%d')\n",
    "\n",
    "# Sort DF by date \n",
    "\n",
    "df.sort_values(by='release_date', ascending=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Stock Market Index Data\n",
    "\n",
    "Since the large majority of US stocks involved the index choosen is the SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-01</td>\n",
       "      <td>1161.060059</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-02</td>\n",
       "      <td>1114.280029</td>\n",
       "      <td>-0.040291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date        Close    return\n",
       "0 2008-10-01  1161.060059       NaN\n",
       "1 2008-10-02  1114.280029 -0.040291"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download SP500 values from Yahoo!\n",
    "\n",
    "gspc=yf.download(['^GSPC'],df['release_date'].iloc[1]-timedelta(2),df['release_date'].iloc[-1]+timedelta(1)).reset_index()[['Date','Close']]\n",
    "\n",
    "# Compute Returns\n",
    "\n",
    "gspc['return']=gspc['Close'].pct_change()\n",
    "\n",
    "# Visual Check \n",
    "\n",
    "gspc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption\n",
    "\n",
    "News and headlines in non-trading days are assigned to the the next trading day. Since 'Close' prices are used to compute returns this assumption rely on the fact that non-trading days news impact the following Close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicates_subset = [ 'title', 'category', 'release_date', 'provider']\n",
    "\n",
    "df_complete = pd.merge_asof(df.drop_duplicates(subset=drop_duplicates_subset), gspc, right_on='Date', left_on='release_date', direction='forward').rename(columns={'Date':'trading_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trading_day</th>\n",
       "      <th>daily_headlines</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-10-02</td>\n",
       "      <td>[Nikkei down 1 4 pct on economy fears  autos d...</td>\n",
       "      <td>-0.040291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-03</td>\n",
       "      <td>[FOREX Dollar poised for biggest weekly gain i...</td>\n",
       "      <td>-0.013507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trading_day                                    daily_headlines    return\n",
       "0  2008-10-02  [Nikkei down 1 4 pct on economy fears  autos d... -0.040291\n",
       "1  2008-10-03  [FOREX Dollar poised for biggest weekly gain i... -0.013507"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group news by the trading day (price) they have impact on  \n",
    "\n",
    "daily_df=df_complete.groupby(by='trading_day').agg({'title':list, 'return':'max'}).reset_index().rename(columns={'title':'daily_headlines'})\n",
    "\n",
    "daily_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Labelling\n",
    "\n",
    "Financial returns based labelling\n",
    "\n",
    "#### Binary\n",
    "\n",
    "binary_label_t = 1 ('Positive') if ret_t >= 0 else 0 ('Negative')\n",
    "\n",
    "#### Ternary\n",
    "\n",
    "What return can be defined as \"neutral\"? \n",
    "\n",
    "This is a tricky question, in this case we assumed ( - 0.2% , + 0.2% ) as neutral interval\n",
    "\n",
    "ternary_label_t = 2 ('Positive') if ret_t >= 0.002 / 1 ('Neutral') if -0.002< ret_t < 0.002 / 0 ('Negative) if ret_t < 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0019856558213586784, -0.0019995427986508885)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary Labelling (Positive/Negative)\n",
    "\n",
    "daily_df['binary_label'] = daily_df['return'].map(lambda x: 1 if x>=0 else 0)\n",
    "\n",
    "# Ternary Labelling (Positive/Neutral/Negative)\n",
    "\n",
    "# Neutral interval ( - 0.2% , + 0.2% )\n",
    "\n",
    "daily_df['ternary_label'] = daily_df['return'].map(lambda x: 2 if x >= 0.002 else 1 if x > -0.002 else 0)\n",
    "\n",
    "# Quick check\n",
    "\n",
    "daily_df[daily_df['ternary_label']== 1]['return'].max(), daily_df[daily_df['ternary_label']== 1]['return'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Text cleaning\n",
    "\n",
    "This phase relies on an object designed to:\n",
    "\n",
    "- remove stopwords\n",
    "- remove punctuation\n",
    "- remove numbers\n",
    "- remove entities\n",
    "- stem words\n",
    "\n",
    "The result should be a cleaned bag-of-words containing all the (stemmed) words coming from all the headlines that affected the trading day outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaner = TextCleaner(spacy_vocab='en_core_web_sm',\n",
    "                           stopwords_adjustments={'-':['above','below','up','down']}, # words having clear financial significance and thus should not be removed\n",
    "                           remove_stopwords=True,\n",
    "                           remove_numbers=True,\n",
    "                           remove_recognized_entities=True,\n",
    "                           remove_punct=True,\n",
    "                           word_red='stem')\n",
    "\n",
    "\n",
    "daily_df['clean_text'] = daily_df['daily_headlines'].map(text_cleaner.clean_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cols = ['trading_day', 'clean_text', 'return', 'binary_label', 'ternary_label']\n",
    "\n",
    "preprocessed_df_filename = 'df_preprocessed.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df[export_cols].to_parquet(os.path.join(data_path, 'intermediate', preprocessed_df_filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
